{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from StackGP import *\n",
    "import sympy as sym\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/nathanhaut/Downloads/pmlb/datasets/195_auto_price/195_auto_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSize=np.floor(len(data)*0.7)\n",
    "testSize=len(data)-trainSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeSymbolicHess(model,vars):\n",
    "    printedModel=sym.simplify(printGPModel(model))\n",
    "    if type(printedModel)==float:\n",
    "        return sym.matrices.dense.MutableDenseMatrix(np.zeros((vars,vars)))\n",
    "    hess=sym.hessian(printedModel, [symbols('x'+str(i)) for i in range(vars)])\n",
    "    return hess\n",
    "\n",
    "def EvaluateHess(hess,vars,values):\n",
    "    numHess=hess.subs({symbols('x'+str(j)):values[j] for j in range(vars)})\n",
    "    hessN = np.array(numHess).astype(float)\n",
    "    rankN=np.linalg.matrix_rank(hessN,tol=0.0001*0.0001*10)\n",
    "    return rankN\n",
    "\n",
    "def Approx2Deriv(model,values,diff1,diff2,positions): #maybe diff should be relative to the variation of each feature\n",
    "    term1=[values[i]+diff1 if i == positions[0] else values[i] for i in range(len(values))]\n",
    "    term1=[term1[i]+diff2 if i == positions[1] else term1[i] for i in range(len(term1))]\n",
    "    term2=[values[i]-diff1 if i == positions[0] else values[i] for i in range(len(values))]\n",
    "    term2=[term2[i]+diff2 if i == positions[1] else term2[i] for i in range(len(term2))]\n",
    "    term3=[values[i]+diff1 if i == positions[0] else values[i] for i in range(len(values))]\n",
    "    term3=[term3[i]-diff2 if i == positions[1] else term3[i] for i in range(len(term3))]\n",
    "    term4=[values[i]-diff1 if i == positions[0] else values[i] for i in range(len(values))]\n",
    "    term4=[term4[i]-diff2 if i == positions[1] else term4[i] for i in range(len(term4))]\n",
    "    return ((evaluateGPModel(model,term1)-evaluateGPModel(model,term2))/((2*diff1))\n",
    "            -(evaluateGPModel(model,term3)-evaluateGPModel(model,term4))/((2*diff1)))/(2*diff2)\n",
    "\n",
    "def ApproxHessRank(model,vars,values,diff1=0.001,diff2=0.001):\n",
    "    hess=[[Approx2Deriv(model,values,diff1,diff2,[i,j]) for i in range(vars)] for j in range(vars)]\n",
    "    hessN = np.array(hess).astype(float)\n",
    "    rankN=np.linalg.matrix_rank(hessN,tol=0.0001*0.0001*10)\n",
    "    return rankN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExperiment(file,targetID,IDrange,name):\n",
    "    #Import data file\n",
    "    data=np.array(pd.read_csv(file))#\"/Users/nathanhaut/Downloads/pmlb/datasets/195_auto_price/195_auto_price.csv\")\n",
    "    \n",
    "    #Extract data from file\n",
    "    #vars=data.columns\n",
    "\n",
    "\n",
    "    #Split train and test data\n",
    "    trainSize=np.floor(len(data)*0.7)\n",
    "    testSize=len(data)-trainSize\n",
    "\n",
    "    trainIndices=np.random.choice(len(data),int(trainSize),replace=False)\n",
    "    testIndices=np.setdiff1d(np.arange(len(data)),trainIndices)\n",
    "\n",
    "    trainData=data.iloc[trainIndices]\n",
    "    testData=data.iloc[testIndices]\n",
    "\n",
    "    #Extract input and response data\n",
    "    trainInput=np.array(trainData.T)[:-1]\n",
    "    trainResponse=np.array(trainData.T)[-1]\n",
    "    testInput=np.array(testData.T)[:-1]\n",
    "    testResponse=np.array(testData.T)[-1]\n",
    "\n",
    "    print(np.abs(trainResponse-np.mean(trainResponse)))\n",
    "    #Get position of max, min, and mean values of response\n",
    "    maxPos=np.argmax(trainResponse)\n",
    "    minPos=np.argmin(trainResponse)\n",
    "    meanPos=np.argmin(np.abs(trainResponse-np.mean(trainResponse)))\n",
    "\n",
    "\n",
    "    #Create target basis set function\n",
    "    func=basisFunctionComplexityDiff(targetID,IDrange,len(trainInput),trainData[minPos][:-1],trainData[maxPos][:-1],trainData[meanPos][:-1])\n",
    "\n",
    "    #Evolve models using three approaches: ID-informed, complexity-informed, and standard tournament\n",
    "    IDmodels=evolve(trainInput,trainResponse,modelEvaluationMetrics=[fitness,func],tourneySize=20,generations=100,align=False,elitismRate=10,popSize=300)\n",
    "    ID3Omodels=evolve(trainInput,trainResponse,modelEvaluationMetrics=[fitness,stackGPModelComplexity,func],tourneySize=40,generations=100,align=False,elitismRate=10,popSize=300)\n",
    "    compModels=evolve(trainInput,trainResponse,tourneySize=20,generations=100,align=False,elitismRate=10,popSize=300)\n",
    "    tourneyModels=evolve(trainInput,trainResponse,modelEvaluationMetrics=[fitness],tourneySize=5,generations=100,align=False,elitismRate=10,popSize=300)\n",
    "\n",
    "    #Select target models from approaches\n",
    "    IDmodel=IDmodels[0]\n",
    "    ID3Omodel=ID3Omodels[0]\n",
    "    compModel=compModels[0]\n",
    "    tourneyModel=tourneyModels[0]\n",
    "\n",
    "    #Align models\n",
    "    IDmodel=alignGPModel(IDmodel,trainInput,trainResponse)\n",
    "    ID3Omodel=alignGPModel(ID3Omodel,trainInput,trainResponse)\n",
    "    compModel=alignGPModel(compModel,trainInput,trainResponse)\n",
    "    tourneyModel=alignGPModel(tourneyModel,trainInput,trainResponse)\n",
    "\n",
    "    #Evaluate models on test data\n",
    "    IDfitness=fitness(IDmodel,testInput,testResponse)\n",
    "    ID3Ofitness=fitness(ID3Omodel,testInput,testResponse)\n",
    "    compFitness=fitness(compModel,testInput,testResponse)\n",
    "    tourneyFitness=fitness(tourneyModel,testInput,testResponse)\n",
    "\n",
    "    IDRMSE=np.linalg.norm(evaluateGPModel(IDmodel,testInput)-testResponse)\n",
    "    ID3ORMSE=np.linalg.norm(evaluateGPModel(ID3Omodel,testInput)-testResponse)\n",
    "    compRMSE=np.linalg.norm(evaluateGPModel(compModel,testInput)-testResponse)\n",
    "    tourneyRMSE=np.linalg.norm(evaluateGPModel(tourneyModel,testInput)-testResponse)\n",
    "\n",
    "    #Save results\n",
    "    results=pd.DataFrame({'ID':[printGPModel(IDmodel),IDfitness,IDRMSE],'ID3O':[printGPModel(ID3Omodel),ID3Ofitness,ID3ORMSE],'Complexity':[printGPModel(compModel),compFitness,compRMSE],'Tourney':[printGPModel(tourneyModel),tourneyFitness,tourneyRMSE]})\n",
    "    results.to_csv('Results/'+name+'.csv')\n",
    "\n",
    "\n",
    "    #Return target models and fitnesses on test data\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrunExperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/nathanhaut/Downloads/pmlb/datasets/195_auto_price/195_auto_price.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mautoPrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m, in \u001b[0;36mrunExperiment\u001b[0;34m(file, targetID, IDrange, name)\u001b[0m\n\u001b[1;32m      3\u001b[0m data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(pd\u001b[38;5;241m.\u001b[39mread_csv(file))\u001b[38;5;66;03m#\"/Users/nathanhaut/Downloads/pmlb/datasets/195_auto_price/195_auto_price.csv\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Extract data from file\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#Split train and test data\u001b[39;00m\n\u001b[1;32m     10\u001b[0m trainSize\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "runExperiment('/Users/nathanhaut/Downloads/pmlb/datasets/195_auto_price/195_auto_price.csv',2,1,'autoPrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTrials(file, count):\n",
    "    #Create variables to store output\n",
    "\n",
    "    #Loop through trials\n",
    "    for i in range(count):\n",
    "        #Run experiments\n",
    "        runExperiment()\n",
    "\n",
    "    #Compute statistics\n",
    "\n",
    "    #Save data to file\n",
    "\n",
    "    #Return results\n",
    "\n",
    "\n",
    "def loadData():\n",
    "    #Load statistics from results file\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
